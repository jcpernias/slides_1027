# -*- ispell-dictionary: "spanish" -*-
#+SETUPFILE: ./course-es.org

#+TITLE: {{{unit08}}} (y II)


#+MATS: bib
#+begin_bibbox
- Wooldridge: ::  /Introducción a la Econometría/. Capítulo 10,
  secciones 10.1, 10.2, 10.4 y 10.5.
- Stock y Watson: ::  /Introducción a la Econometría/. Capítulo 14,
  secciones 14.1 a 14.5.
#+end_bibbox


* Introducción


** Algunos procesos estocásticos

Examinaremos las principales características de algunos procesos
estocásticos importantes:

- Ruido blanco.

- Procesos autorregresivos.

- Paseo aleatorio.

- Procesos integrados.


* Ruido blanco


** Definición

El proceso estocástico $\{e_t\}$ es un *ruido blanco* si:

- $\Exp(e_t) = 0$.

- $\var(e_t) = \sigma^2_e < \infty$.

- $\cov(e_{t+h}, e_t) = 0$, para todo $h > 0$.


** Ejemplo

Ruido blanco, $\sigma^2_e = 4$, $T = 60$.

#+MATS: fig fig-08b_1027-wn-ts-*.pdf


** Características

- Un ruido blanco es un proceso estacionario y débilmente
  estacionario.

- Conocer los valores pasados de un ruido blanco no ayuda a predecir
  mejor $e_t$:
  #+begin_export latex
  \[
    \Exp(e_t | e_{t-1}, e_{t-2}, \dots) = \Exp(e_t) = 0.
  \]
  #+end_export

- Un ruido blanco no tiene *memoria*: el valor que toma en un periodo no
  tienen ninguna influencia sobre los valores futuros.


** Autocorrelación

#+MATS: figcol fig-08b_1027-wn-lag-*.pdf 0.5

- $e_t$ no está correlacionado con sus retardos.

- Los coeficientes de autocorrelación de un ruido blanco son todos
  iguales a 0: $\rho_h = 0$, para todo $h > 0$.


** Relación con otros conceptos

- Un ruido blanco es un proceso *i.i.d.* (independiente e
  idénticamente distribuido).

- En algunos campos coincide con el concepto de *innovaciones*.

- Un *ruido blanco gaussiano*, además de las anteriores, cumple la
  condición:
  #+begin_export latex
  \[
    e_t \sim \Normal(0, \sigma^2_e)
  \]
  #+end_export


* Procesos autorregresivos


** Procesos autorregresivos

- El valor presente de un *proceso autorregresivo* depende de los
  valores que tomó el proceso en periodos anteriores.

- Un proceso autorregresivo de orden $p$, AR($p$), cumple la siguiente
  ecuación:
  #+begin_export latex
  \[
    y_{t} = \rho_{1} y_{t-1} + \rho_{2} y_{t-2} + \dots \rho_{p} y_{t-p} + e_{t},
  \]
  #+end_export
  donde $\rho_1, \rho_2, \dots, \rho_p$ son parámetros y $\{e_t\}$ es
  un ruido blanco. El valor inicial de la secuencia es 0: $y_0 = 0$.


** Proceso AR(1)

- Nos centraremos en el proceso autorregresivo de orden 1, AR(1):
  #+begin_export latex
  \[
    y_{t} = \rho y_{t-1} +  e_{t},
  \]
  #+end_export

- La *condición de estabilidad* de un proceso AR(1) es:
  #+begin_export latex
  \[
    \abs{\rho} < 1
  \]
  #+end_export

- Un *proceso AR estable* es estacionario y débilmente dependiente.


** Esperanza de un proceso AR(1)

- $y_t$ sigue un proceso AR(1): $y_{t} = \rho y_{t-1} +  e_{t}$.

- Tomando esperanzas:
  #+begin_export latex
  \[
    \Exp(y_{t}) = \rho \Exp(y_{t-1}) +  \Exp(e_{t}).
  \]
  #+end_export

- Si $y_t$ es estacionario: $\Exp(y_t) = \Exp(y_{t-1})œ$. Por otro
  lado, $\Exp(e_t) = 0$. Por tanto, la expresión anterior se reduce a:
  #+begin_export latex
  \[
     \Exp(y_{t}) = \rho \Exp(y_{t}).
  \]
  #+end_export

- Para que la ecuación anterior sea cierta para cualquier $\rho$, se
  tiene que cumplir que $\Exp(y_t) = 0$.


** Varianza de un proceso AR(1)

- $y_t$ sigue un proceso AR(1): $y_{t} = \rho y_{t-1} +  e_{t}$.

- La varianza de $y_t$ es:
  #+begin_export latex
  \[
     \var(y_{t}) = \rho^2 \var(y_{t-1}) + \var(e_t).
  \]
  #+end_export

- Si $y_t$ es estacionario, $\var(y_{t}) = \var(y_{t-1}) =
  \sigma^2_y$. Podemos escribir la expresión anterior como:
  #+begin_export latex
  \[
     \sigma^2_y = \rho^2 \sigma^2_y + \sigma^2_e.
  \]
  #+end_export

- Finalmente, la varianza de $y_t$ es:
  #+begin_export latex
  \[
     \sigma^2_y = \frac{\sigma^2_e}{1 - \rho^2}.
  \]
  #+end_export


** Autocovarianzas de un proceso AR(1) (I)

- Ya que $\Exp(y_t) = 0$, la autocovarianza de $y_{t+h}$ e $y_ {t}$ es:
  #+begin_export latex
  \[
    \cov(y_{t+h}, y_t) = \Exp(y_{t+h}  y_t)
  \]
  #+end_export

- Cuando $h = 1$:
  #+begin_export latex
  \[
    \cov(y_{t+1}, y_t) = \Exp(y_{t+1}  y_t)
  \]
  #+end_export

- Sustituyendo $y_{t+1} = \rho y_t + e_{t+1}$:
  #+begin_export latex
  \[
    \cov(y_{t+1}, y_t) =
    \Exp\!\big[(\rho y_t + e_{t+1}) y_t\big] =
    \Exp\!\big[\rho y^{2}_t + y_t e_{t+1} \big]
  \]
  #+end_export

- Teniendo en cuenta que $\Exp(y^2_t) = \sigma^2_y$ y que $\Exp(y_t e_s) =
  0$ para $t \neq s$:
  #+begin_export latex
  \[
    \cov(y_{t+1}, y_t) = \rho \sigma^2_y.
  \]
  #+end_export


** Autocovarianzas de un proceso AR(1) (II)

- Ahora escribimos el proceso autorregresivo para $t+2$:
  #+begin_export latex
  \[
    y_{t + 2} = \rho y_{t + 1} +  e_{t + 2}.
  \]
  #+end_export

- Sustituimos $y_{t+1} = \rho y_t + e_{t+1}$:
  #+begin_export latex
  \[
    y_{t + 2} = \rho^2 y_{t} + \rho e_{t+1}+  e_{t + 2}.
  \]
  #+end_export

- La autocovarianza de $y_{t+2}$ e $y_ {t}$ es:
  #+begin_export latex
  \[
    \cov(y_{t+2}, y_t) = \Exp(y_{t+2}  y_t) =
    \Exp\!\big[(\rho^2 y_{t} + \rho e_{t+1}+  e_{t + 2}) y_t\big].
  \]
  #+end_export

- Finalmente:
  #+begin_export latex
  \[
    \cov(y_{t+2}, y_t) = \rho^2 \sigma^2_y.
  \]
  #+end_export


** Autocovarianzas de un proceso AR(1) (y III)

- Mediante sustitución recursiva obtenemos:
  #+begin_export latex
  \[
    y_{t + h} =
    \rho^h y_{t} +
    \rho^{h-1} e_{t+1}  +
    \rho^{h-2} e_{t+2} + \dots +
    \rho e_{t+h-1} +
    e_{t + h}.
  \]
  #+end_export

- La autocovarianza de $y_{t+h}$ e $y_ {t}$ es:
  #+begin_export latex
  \[
    \cov(y_{t+h}, y_t) =
    \Exp\!\big[(\rho^h y_{t} +
    \rho^{h-1} e_{t+1}  +
    \dots +
    e_{t + h})
    y_t\big].
  \]
  #+end_export

- Dado que $\Exp(y^2_t) = \sigma^2_y$ y que $\Exp(y_t e_s) = 0$ para $t \neq
  s$:
  #+begin_export latex
  \[
    \cov(y_{t+h}, y_t) = \rho^h \sigma^2_y.
  \]
  #+end_export


** Autocorrelaciones de un proceso AR(1)

- Autocorrelación entre $y_{t+h}$ e $y_ {t}$:
  #+begin_export latex
  \[
    \corr(y_{t+h}, y_{t}) = \frac{\cov(y_{t+h}, y_{t})}{
      \sqrt{\var(y_{t+h})\var(y_{t})}
    }
  \]
  #+end_export

- Teniendo en cuenta que
  #+begin_export latex
  \begin{gather*}
    \var(y_{t+h}) = \var(y_{t}) = \sigma^2_y, \\
    \intertext{y que}
    \cov(y_{t+h}, y_{t}) = \rho^h \sigma^2_y, \\
    \intertext{se obtiene:}
    \corr(y_{t+h}, y_{t}) = \rho^h.
  \end{gather*}
  #+end_export


** Estacionariedad y dependencia débil

- $y_t$ sigue un proceso AR(1):
  #+begin_export latex
  \[
    y_{t} = \rho y_{t-1} +  e_{t},
  \]
  #+end_export


- Si $\abs{\rho} < 1$, $y_t$ es un proceso estacionario:

  + $\Exp(y_t) = 0$.

  + $\var(y_t) = \sigma^2_e / (1 - \rho^2)$.

  + $\cov(y_{t+h}, y_{t}) = \rho^h \sigma^2_y$, para $h > 0$.

- Si $\abs{\rho} < 1$ el proceso AR(1) es débilmente dependiente,
  puesto que $\corr(y_{t+h}, y_t) = \rho^h$ converge a 0 conforme $h
  \to \infty$ y la convergencia es geométrica.


** Algunos ejemplos (I)

Proceso AR(1), $\rho = 0.8$, $\sigma^2_e = 4$, $T = 60$.
#+MATS: fig fig-08b_1027-ar8-ts-*.pdf

Proceso AR(1), $\rho = 0.2$, $\sigma^2_e = 4$, $T = 60$.
#+MATS: fig fig-08b_1027-ar2-ts-*.pdf


** Algunos ejemplos (y II)

#+MATS: col 0.5
Proceso AR(1), $\rho = 0.8$, $\sigma^2_e = 4$, $T = 60$.
#+MATS: fig fig-08b_1027-ar8-lag-*.pdf

#+MATS: col 0.5
Proceso AR(1), $\rho = 0.2$, $\sigma^2_e = 4$, $T = 60$.
#+MATS: fig fig-08b_1027-ar2-lag-*.pdf


* Paseo aleatorio


** Definición

Un *paseo aleatorio* es un proceso estocástico que se puede expresar
como:
#+begin_export latex
\[
   y_t = y_{t-1} + e_t,
\]
#+end_export
donde $e_t$ es un ruido blanco.


** Sustitución recursiva

Sustituyendo recursivamente se obtiene:
#+begin_export latex
\[
  y_t = e_t + e_{t-1} + \dots + e_1 + y_0,
\]
#+end_export
donde $y_0$ es el valor inicial del proceso. Supondremos que $y_0 =
0$, por lo que:
#+begin_export latex
\[
  y_t = e_t + e_{t-1} + \dots + e_1.
\]
#+end_export


** Esperanza y varianza

- La esperanza de un paseo aleatorio es 0:
  #+begin_export latex
  \[
    \Exp(y_t) =  \Exp(e_t) +  \Exp(e_{t-1}) + \dots +  \Exp(e_1) = 0.
  \]
  #+end_export


- La varianza de un paseo aleatorio es creciente en el tiempo:
  #+begin_export latex
  \[
    \var(y_t) =  \var(e_t) +  \var(e_{t-1}) + \dots +  \var(e_1) = t \sigma^2_e.
  \]
  #+end_export


** Autocovarianzas y autocorrelaciones

- La autocovarianza entre $y_{t+h}$ e $y_t$ es:
  #+begin_export latex
  \[
    \cov(y_{t+h}, y_t) = \Exp(y_{t+h} y_t) =
    \Exp\!\big[( y_{t} + e_{t+1}  + \dots + e_{t + h}) y_t\big]  = t \sigma^2_e.
  \]
  #+end_export

- La autocorrelación entre $y_{t+h}$ e $y_t$ es:
  #+begin_export latex
  \[
    \corr(y_{t+h}, y_t) = \sqrt{\frac{t}{t+h}}
  \]
  #+end_export


** No estacionariedad

Un paseo aleatorio no cumple las condiciones de la estacionariedad
débil:

- $\Exp(y_t) = 0$.

- $\var(y_t) = t \sigma^2_e$.

- $\cov(y_{t+h}, y_{t}) = t \sigma^2_e$, para $h > 0$.


** Dependencia fuerte

- Las autocorrelaciones de un paseo aleatorio son:
  #+begin_export latex
  \[
    \corr(y_{t+h}, y_t) = \sqrt{\frac{t}{t+h}}
  \]
  #+end_export

- $\corr(y_{t+h}, y_t)$ converge a 0 conforme $h \to \infty$, pero la
  convergencia es muy lenta.


** Ejemplo

Paseo aleatorio, $\sigma^2_e = 4$, $T = 60$.

#+MATS: fig fig-08b_1027-rw-ts-*.pdf



* Tendencias


** Paseo aleatorio con deriva

- Un *paseo aleatorio con deriva* se puede expresar como:
  #+begin_export latex
  \[
     y_t = \alpha_0 + y_{t-1} + e_t,
  \]
  #+end_export
  donde $e_t$ es un ruido blanco y el parámetro $\alpha_0$ es el
  *término de deriva*.

- Sustituyendo recursivamente y teniendo en cuenta que $y_0 = 0$:
  #+begin_export latex
  \[
    y_t = \alpha_0 t + e_t + e_{t-1} + \dots + e_1.
  \]
  #+end_export

- El valor esperado de $y$ es función de $t$:
  #+begin_export latex
  \[
     \Exp(y_t) = \alpha_0 t
  \]
  #+end_export


** Ejemplo

Paseo aleatorio con deriva, $\alpha_0 = 1$, $\sigma^2_e = 4$, $T = 60$.

#+MATS: fig fig-08b_1027-rwd-ts-*.pdf


** Procesos estacionarios con tendencia

- Los paseos aleatorios con deriva no son los únicos procesos que
  presentan tendencias.

- Un *proceso estacionario con tendencia* puede escribirse como:
  #+begin_export latex
  \[
    y_t = \beta_0 + \beta_1 t + u_t,
  \]
  #+end_export
  donde $u_t$ es un proceso estacionario y débilmente dependiente.


** Ejemplo

$y_t = \beta_0 + \beta_1 t + u_t$, $\beta_1 = 1$, $u_t \sim AR(1)$, $T = 60$.

#+MATS: fig fig-08b_1027-tst-ts-*.pdf



* Procesos integrados


** La diferencia de un paseo aleatorio

- Un paseo aleatorio puede escribirse como:
  #+begin_export latex
  \[
    y_t = y_{t-1} + e_t
  \]
  #+end_export

- Restando $y_{t-1}$ de ambos lados:
  #+begin_export latex
  \[
    y_t - y_{t-1} = e_t
  \]
  #+end_export

- La diferencia de un paseo aleatorio es un ruido blanco:
  #+begin_export latex
  \[
     \incr y_t = e_t
  \]
  #+end_export


** Diferencias y dependencia débil

- La diferencia de un paseo aleatorio es un ruido blanco, un proceso
  débilmente dependiente.

- Existen otros procesos estocásticos que, después de diferenciarlos,
  son débilmente dependientes.


** Procesos integrados

- El proceso $y_t$ es *integrado de orden 1*, I(1), si $y_t$ es un
  proceso altamente persistente, pero su diferencia, $\incr y_t$, es
  débilmente dependiente.

- Si es necesario diferenciar dos veces para obtener un proceso
  débilmente dependiente, el proceso $y_t$ es *integrado de orden 2*,
  I(2).

- Un proceso débilmente dependiente es *integrado de orden 0*, I(0),
  puesto que no es necesario aplicar ninguna diferencia.

** Ejemplo: IPC armonizado

Logaritmo del IPC armonizado de España, febrero de 1998 hasta febrero
de 2023. Fuente: INE.

#+MATS: fig fig-08b_1027-lp-ts-*.pdf

** Ejemplo: Inflación interanual

Tasa de inflación interanual:
#+begin_export latex
\[
  \pi_t = 100 \incr_{12} \log(p_t) = 100 \big(\log(p_t) - \log(p_{t-12})\big).
\]
#+end_export
#+MATS: fig fig-08b_1027-infl-ts-*.pdf

** Ejemplo: Variación mensual de la inflación

Variación mensual de la inflación:
#+begin_export latex
\[
  \incr \pi_t = \pi_t - \pi_{t-1}.
\]
#+end_export
#+MATS: fig fig-08b_1027-dinfl-ts-*.pdf

** Ejemplo: Procesos integrados

- El índice de precios es altamente persistente. Al tomar diferencias
  se obtiene la tasa de inflación que también es altamente
  persistente. La variación de la tasa de inflación se comporta como
  un proceso débilmente dependiente.

- Las tres series tienen diferentes órdenes de integración:
  #+begin_export latex
  \begin{gather*}
    \log(p_{t}) \sim \text{I}(2), \\
    \pi_{t} \sim \text{I}(1), \\
    \incr \pi_{t} \sim \text{I}(0).
  \end{gather*}
  #+end_export
