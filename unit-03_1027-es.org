# -*- ispell-dictionary: "spanish" -*-
#+SETUPFILE: ./course-es.org

#+TITLE: {{{unit03}}}

#+MATS: bib
#+begin_bibbox
- Wooldridge: ::  /Introducción a la Econometría/. Capítulo 5.
#+end_bibbox

* Introducción


** El supuesto de normalidad

El supuesto *RLM.6* del modelo clásico de regresión requiere la
normalidad del término de error:
#+begin_export latex
\[
  u \sim \Normal(0, \sigma^{2}).
\]
#+end_export


** Inferencia en el modelo clásico

El supuesto de normalidad permite conocer la distribución de los
contrates de hipótesis bajo la hipótesis nula.


** Falta de normalidad

En muchos casos el supuesto de normalidad no es muy razonable:

- Variable dependiente sólo toma valores positivos.

- Variable dependiente sólo toma algunos valores discretos.


** Teoría asintótica

La *teoría asintótica* estudia el comportamiento de estimadores y
contrastes de hipótesis cuando el tamaño muestral crece
indefinidamente.


** Teoremas sobre límites

Bajo ciertas condiciones, secuencias de variables aleatorias obtenidas
por muestreo aleatorio cumplen conforme $n \to \infty$:

- *Leyes de grandes números*: establecen la convergencia de medias
  muestrales a la media poblacional.

- *Teoremas del límite central*: establecen la *distribución
  asintótica* de las medias muestrales.


** Propiedades asintóticas

- *Consistencia*.

- *Distribución asintótica*.

- *Eficiencia asintótica*.


** Consistencia

Un estimador es consistente si conforme aumenta el tamaño muestral
converge en probabilidad al parámetro poblacional:
#+begin_export latex
\[
   \plim \bhat_j = \beta_j.
\]
#+end_export

Intuitivamente, cuanto mayor es el tamaño muestral más cerca está un estimador consistente del parámetro poblacional


** Consistencia e insesgadez

- Las propiedades de consistencia e insesgadez son independientes: una
  no implica la otra.

- Un estimador es consistente si es insesgado y su varianza decrece y
  converge a 0 conforme aumenta el tamaño muestral.


** Distribución asintótica

- La *distribución asintótica* de un estimador es su distribución en
  el límite.

- Proporciona una aproximación a la distribución del estimador para un
  tamaño muestral finito.


** Normalidad asintótica

- Un estimador es *asintóticamente normal* si su distribución
  asintótica es normal.

- No es necesaria la normalidad del término de error, basta con que se
  cumplan las condiciones de un teorema del límite central.


** Consideraciones prácticas

- Las propiedades asintóticas no requieren el supuesto de normalidad.

- Requisitos técnicos: momentos finitos hasta orden 4. Supondremos
  implícitamente que se cumple.

- La calidad de las aproximaciones asintóticas suele mejorar con el
  tamaño muestral. Pero, ¿cuántas observaciones son necesarias en la
  práctica?


* Propiedades asintóticas de MCO



** Consistencia

- MCO es consistente si se cumplen los supuestos *RLM.1* a *RLM.4*.

- El supuesto *RLM.4*, $E(u|\bm{x}) = 0$, puede relajarse y basta con:
  #+begin_export latex
  \[
    \Exp(u) = 0 \stext{y} \cov(x_{j}, u) \text{\ para $j = 1, 2, \dots, k$}.
  \]
  #+end_export


** Inconsistencia

- La *inconsistencia* de $\bhat_i$ es la diferencia entre el límite
  del estimador y el parámetro poblacional. En el caso de MCO:
  #+begin_export latex
  \[
    \plim \bhat_{i} - \beta_{i} = \frac{\cov(x_{i}, u)}{\var(x_{i})}.
  \]
  #+end_export

- MCO es *inconsistente* si el término de error y, al menos, una de
  las explicativas están correlacionados.


** Variable relevante omitida

- Se cumplen los supuestos *RLM.1* a *RLM.4* en el modelo poblacional:
  #+begin_export latex
  \[
    y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + u.
  \]
  #+end_export

- Si se omite la variable $x_2$, el sesgo del estimador MCO de
  $\beta_1$ es:
  #+begin_export latex
  \[
    \plim \bhat_{1} - \beta_{1} = \beta_2 \delta_{21},
  \]
  #+end_export
  donde $\delta_{21} = \cov(x_1, x_2) / \var(x_1)$, mide la intensidad
  de la asociación de las variables $x_2$ y $x_1$.

- Omitir una variable relevante, $\beta_2 \neq 0$, causa
  inconsistencia si la variable omitida está correlacionada con alguna
  de las explicativas, $\delta_{21} \neq 0$.


** Varianza de los estimadores MCO

Si se cumplen los supuestos de Gauss-Markov, *RLM.1* a *RLM.5*:

- $\hat{\sigma}^2$ es un estimador consistente de $\var(u)$.

- Las fórmulas para estimar las varianzas de los estimadores MCO son
  válidas asintóticamente:
  #+begin_export latex
  \[
    \widehat{\var}(\bhat_{j}) = \frac{\hat{\sigma}^2}{\SCT_{j}(1-\Rsq_{j})}.
  \]
  #+end_export


** Normalidad asintótica del estimador MCO

Si se cumplen los supuestos de Gauss-Markov, *RLM.1* a *RLM.5*, la distribución asintótica del estimador MCO es normal:
  #+begin_export latex
  \[
    \frac{\bhat_{j} - \beta_{j}}{\sd(\bhat_{j})} \adistr \Normal(0, 1),
    \text{\ para $j = 0, 1, 2, \dots, k$}.
  \]
  #+end_export



* Inferencia asintótica


** Contraste de hipótesis en muestras grandes

- No es necesario el supuesto de normalidad del término de error para
  usar los contrastes $t$ y $F$.

- Disponemos de otros contrastes que sólo son válidos asintóticamente.


** Contrastes $t$

- Si se cumplen los supuestos de Gauss-Markov, podemos usar la
  distribución $t$ para determinar valores críticos y los valores-$p$
  de los contrates $t$.
  #+begin_export latex
  \[
    \frac{\bhat_{j} - \beta_{j}}{\se(\bhat_{j})} \adistr t_{n - k - 1}.
  \]
  #+end_export


** Intervalos de confianza

- Si se cumplen los supuestos de Gauss-Markov, podemos usar la fórmula
  habitual para obtener un intervalo a un nivel de confianza $1 -
  \alpha$ para el parámetro $\beta_j$:
  #+begin_export latex
  \[
    \bhat_j \pm c_{\alpha/2} \cdot \se(\bhat_j),
  \]
  #+end_export
  donde $c_{\alpha/2}$ es el valor crítico de dos colas de una
  distribución $t_{n-k-1}$ a un nivel de significación $\alpha$.


** Contrastes $F$

- Si se cumplen los supuestos de Gauss-Markov, podemos usar la
  distribución $F$ para determinar valores críticos y los valores-$p$
  de los contrates $F$.
  #+begin_export latex
  \[
    \frac{(\SCRr - \SCRnr) / q}{\SCRnr / (n - k - 1)}  \adistr F_{q,\, n - k - 1}.
  \]
  #+end_export


** Otros contrastes asintóticos

Se han propuesto otros principios de contrastación de restricciones
generales sobre los parámetros y que sólo tienen validez asintótica:

- *Contrastes de Wald*.

- *Contrastes de multiplicadores de Lagrange*.

- *Contrastes de la razón de verosimilitudes*.


** Contrastes de Wald

- Los *contrastes de Wald* pueden interpretarse como una
  generalización de los contrastes $t$.

- Sólo requieren la estimación del modelo no restringido.

- Bajo la $H_0$ se distribuyen como una $\chi^2$ con $q$ grados de
  libertad. También se usan versiones de este contraste que se
  distribuyen como una $F_{q,\, n - k - 1}$.


** Contrastes de multiplicadores de Lagrange

- Para utilizar un *contraste de multiplicadores de Lagrange*, $\LM$,
  sólo es necesaria la estimación del modelo restringido.

- Son especialmente útiles cuando la estimación del modelo no
  restringido es difícil.

- Frecuentemente se calculan a partir de una *regresión auxiliar*.


** Contraste de variables omitidas

- Modelo de regresión poblacional que cumple *RLM.1* a *RLM.5*:
  #+begin_export latex
  \[
    y = \beta_0 + \beta_1 x_1  + \beta_2 x_2  + \beta_3 x_3  + \beta_4 x_4 + u.
  \]
  #+end_export

- Estamos interesados en contrastar la hipótesis nula
  #+begin_export latex
  \[
    H_0\!: \beta_3 = \beta_4 = 0.
  \]
  #+end_export



** Contraste $\LM$ de variables omitidas

- Estimación del modelo restringido por MCO:
  #+begin_export latex
  \[
    y = \bhat_0 + \bhat_1 x_1  + \bhat_2 x_2 + \uhat.
  \]
  #+end_export

- *Regresión auxiliar* usando los residuos como variable dependiente y
  todas las explicativas, tanto incluidas como excluidas:
  #+begin_export latex
  \[
    \uhat \text{\ sobre $x_1, x_2, x_3, x_4$}.
  \]
  #+end_export

- El estadístico de contraste es $\LM = n \Rsq_{aux}$: el número de
  observaciones multiplicado por el $\Rsq$ de la regresión auxiliar.


** Regla de decisión

Si la hipótesis nula que impone $q$ restricciones es correcta:

- El estadístico $\LM$ se distribuye asintóticamente como una
  $\chi^2$ con $q$ grados de libertad:
  #+begin_export latex
  \[
    n \Rsq_{aux} \adistr \chi^2_q.
  \]
  #+end_export

- Una versión alternativa del contraste utiliza un estadístico $F$
  para contrastar restricciones de exclusión en la regresión auxiliar.


** Contrastes de razón de verosimilitudes

- Se pueden interpretar como una generalización del contraste $F$.

- Requieren la estimación del modelo restringido y del modelo no
  restringido.

- Son útiles cuando en modelos no lineales que se estiman con métodos
  diferentes a MCO.
