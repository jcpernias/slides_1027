# -*- ispell-dictionary: "spanish" -*-
#+SETUPFILE: ./course-es.org

#+TITLE: {{{unit01}}}

#+MATS: bib
#+begin_bibbox
- Wooldridge: ::  /Inroducción a la Econometría/. Capítulos 3, 4, 6 y 7.
#+end_bibbox

#+PROPERTY: header-args:R :session *R* :exports results :results output :eval yes
#+PROPERTY: header-args:R :var orgbackend=(prin1-to-string org-export-current-backend)
#+MACRO: Rtable (eval (concat "#+header: :results output " (prin1-to-string org-export-current-backend)))

* El modelo clásico de regresión lineal

** Supuestos

- *RLM.1*: Linealidad en los parámetros.

- *RLM.2*: Muestreo aleatorio.

- *RLM.3*: Ausencia de multicolinealidad perfecta.

- *RLM.4*: Media condicional nula.

- *RLM.5*: Homoscedasticidad.

- *RLM.6*: Normalidad.

** RLM.1: Linealidad en los parámetros

El modelo *poblacional* puede expresarse como:
#+begin_export latex
\[
  y = \beta_{0} + \beta_{1} x_{1} + \dots + \beta_{k} x_{k} + u
\]
#+end_export
donde $\beta_0, \beta_0, \dots, \beta_k$ son los *parámetros*
desconocidos, $y$ es la *variable dependiente*, $x_1, x_2, \dots, x_k$
son las *variables explicativas* y $u$ es un *término de error* no
observable.

** RLM.2: Muestreo aleatorio

Disponemos de una muestra aleatoria de n observaciones:
#+begin_export latex
\[
  \{(x_{1i}, x_{2i}, \dots, x_{ki}, y_{i}); i = 1, 2, \dots, n \}
\]
#+end_export

** RLM.3: No hay colinealidad perfecta

En la muestra se cumplen *todas* las condiciones:

- El número de observaciones, $n$, es mayor que el número de
  parámetros, $k + 1$.

- Ninguna de las variables explicativas es constante.

- No existen *relaciones lineales exactas* entre las variables
  explicativas.

** RLM.4: Media condicional nula

El valor esperado del término de error para cualquier combinación de
valores que tomen las variables explicativas es 0:
#+begin_export latex
\[
  \Exp(u | x_{1}, x_{2}, \dots, x_{k}) = 0
\]
#+end_export

** RLM.5: Homoscedasticidad

La varianza del término de error no depende de los valores
que tomen las explicativas:
#+begin_export latex
\[
  \var(u | x_{1}, x_{2}, \dots, x_{k}) = \sigma^{2}
\]
#+end_export

** RLM.6: Normalidad

El término de error es independiente de las variables explicativas y
su distribución es normal con media 0 y varianza $\sigma^2$:
#+begin_export latex
\[
  u \sim \Normal(0, \sigma^{2})
\]
#+end_export

* Estimación


** Estimación por MCO

- Ecuaciones normales:
  #+begin_export latex
  \begin{gather*}
    \sum \uhat_{i} = 0 \\
    \sum \uhat_{i} x_{1\,i} = 0 \\
    \vdotswithin{\sum} \\
    \sum \uhat_{i} x_{k\,i} = 0 \\
  \end{gather*}
  #+end_export


** Bondad del ajuste

- Error típico de la regresión, $\SER$.

- Coeficiente de determinación, $\Rsq$.

- $\Rsq$ ajustado, $\Rbarsq$.


* Propiedades del estimador de MCO


** Propiedades de muestras pequeñas

- Insesgadez.

- Distribución muestral.

- Eficiencia.


* Inferencia


** Conceptos básicos

- Hipótesis nula e hipótesis alternativa.

- Error tipo I.

- Error tipo II.

- Regla de rechazo.


** Más conceptos básicos

- Nivel de significación.

- Potencia.

- Valor crítico.

- $\pvalue$.


** Contraste de hipótesis

- Hipótesis combinaciones lineales de los parámetros del modelo.

- Hipótesis simples e hipótesis compuestas.

- Modelo general y modelo restringido.


** El contraste /t/

- Aplicabilidad.

- Construcción.

- Distribución bajo la hipótesis nula.

- Sólo necesita la estimación del modelo general.

- Generalización a hipótesis compuestas: contraste de Wald.


** El contraste /F/

- Aplicabilidad.

- Construcción.

- Distribución bajo la hipótesis nula.

- Se necesita la estimación del modelo general y del modelo restringido.


** Algunos casos especiales

- El estadístico $t$:
  #+begin_export latex
  \[
    t_{\bhat_{j}} = \frac{\bhat_{j}}{\se(\bhat_{j})}
  \]
  #+end_export

- El estadístico $F$ de significación conjunta de la regresión:
  #+begin_export latex
  \[
    F = \frac{\Rsq / k}{(1 - \Rsq) / (n - k - 1)}
  \]
  #+end_export


** Intervalos de confianza

- Construcción.


* Predicción


** Predicción puntual

- Predicción del valor medio.

- Predicción del valor.


** Intervalos de predicción

- Valor medio.

- Valor de la variable dependiente.
