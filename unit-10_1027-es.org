# -*- ispell-dictionary: "spanish" -*-
#+SETUPFILE: ./course-es.org

#+TITLE: {{{unit10}}}

#+MATS: bib
#+begin_bibbox
- Wooldridge: ::  /Introducción a la Econometría/. Capítulos 10.4,
  10.5, 11.3, 18.2 y 18.3.
- Stock y Watson: :: /Introducción a la Econometría/. Capítulos 14.5,
  14.6, 14.7 y 15.3.
#+end_bibbox


* Selección del número de retardos


** Introducción

- Modelo ARDL($p$, $q$):
  #+begin_export latex
  \[
     y_t = \alpha + \rho_1 y_{t-1} + \dots + \rho_p y_{t-p} +
     \beta_0 z_t + \beta_1 z_{t-1} + \dots + \beta_q z_{t-q} +
     u_t
  \]
  #+end_export

- ¿Cuántos retardos hay que incluir en una regresión de series
  temporales?

- ¿Qué métodos podemos usar para determinar el número de retardos?


** Selección de retardos

- Si se selecciona un número demasiado pequeño de retardos se
  omite información relevante.

- Con un número demasiado grande se pierde eficiencia.


** Selección de modelos

- Se establece un número máximo de retardos a considerar procurando
  que sea lo suficientemente elevado para capturar todas las
  relaciones dinámicas.

- Se estiman modelos de regresión con diferente número de
  retardos. *La muestra debe ser la misma en todas las regresiones*.

- Se utiliza algún indicador para determinar cuál es el modelo más
  adecuado.


** Contrastes F

- Se contrasta la significación del último retardo usando un
  contraste $F$. Si el último retardo no es significativo, se estima
  un nuevo modelo sin ese retardo y se vuelve a repetir el proceso.

- Los contrastes $F$ no están diseñados para seleccionar modelos y el
  procedimiento tiende a seleccionar más retardos de los necesarios.


** Criterios de información

- En la selección de modelos se suele usar algún *criterio de
  información*: medidas de la bondad del ajuste que incluyen una
  penalización creciente en el número de parámetros.

- Se estiman todos los modelos con diferente número de retardos que se
  quieran comparar. Se selecciona aquel con un menor valor del
  criterio de información.


** Algunos criterios de información

- *AIC*: criterio de información de Akaike. En los modelos de regresión puede escribirse como:
  #+begin_export latex
  \[
     \text{AIC} = C + T \log\left(\frac{\SCR}{T}\right) + 2 (K + 1),
  \]
  #+end_export
  donde $C$ es una constante, $T$ es el número de observaciones,
  $\SCR$ es la suma del cuadrado de los residuos y $K$ es el número de
  parámetros.

- *BIC*: criterio de información bayesiano.
  #+begin_export latex
  \[
     \text{BIC} = C + T \log\left(\frac{\SCR}{T}\right) + \log(T) (K + 1).
  \]
  #+end_export
  Se diferencia del AIC en que penaliza más el número de parámetros.


** Comparación entre criterios

- Usando el BIC se obtiene una estimación consistente del número de
  retardos.

- El AIC produce resultados similares aunque suele seleccionar un
  número de retardos mayor que el BIC.



* Regresión espuria

** Regresión espuria en cortes transversales

- Dos variables, $y$ y $x$, parecen estar muy correlacionadas y la
  regresión de $y$ sobre $x$ produce resultados significativos.

- La relación entre $y$ y $x$ desaparece cuando se incluye una tercera
  variable, $z$, en la regresión.

- La regresión de $y$ sobre $x$ es un ejemplo de *regresión espuria*.


** Regresión espuria en series temporales

- La omisión de variables relevantes también puede producir
  regresiones espurias con datos de series temporales.

- Además, es muy frecuente encontrar regresiones espurias cuando se
  incluyen series temporales con tendencia o que sean altamente
  persistentes.


** Tipos de tendencia

La *tendencia* de una serie temporal está constituida por movimientos
persistentes a largo plazo. Distinguimos entre:

- Tendecias deterministas.

- Tendencias estocásticas.


** Tendencias deterministas

- Una *tendencia determinista* es una función no aleatoria del tiempo.

- Por ejemplo, si $y_t$ fluctúa alrededor de una *tendencia lineal*:
  #+begin_export latex
  \[
    y_t = \alpha + \delta t + u_t,
  \]
  #+end_export
  donde $u_t$ es un proceso estacionario y débilmente dependiente.

** Regresión y tendencias lineales

- Regresión con dos variables, $y_t$ y $x_t$, las cuales no están
  relacionadas pero presentan *tendencias lineales*:
  #+begin_export latex
  \[
    y_t = \alpha + \beta x_t + u_t.
  \]
  #+end_export

- A pesar de que $\beta = 0$, la regresión anterior con frecuencia
  indicaría que existe una relación significativa entre las dos
  variables.

- Para evitar encontrar regresiones espurias, es aconsejable
  introducir una tendencia lineal en la regresión anterior:
  #+begin_export latex
  \[
    y_t = \alpha + \beta x_t + \delta t + u_t.
  \]
  #+end_export

** Tendencias estocásticas

- Una *tendencia estocástica* es aleatoria y varía con el paso del
  tiempo.

- El ejemplo más simple de una variable con tendencia estocástica es
  el *paseo aleatorio*:
  #+begin_export latex
  \[
    y_t = y_{t-1} + e_t.
  \]
  #+end_export

- Un paseo aleatorio alterna episodios de crecimiento durante varios
  periodos, con episodios donde la tendencia es decreciente.

** Paseo aleatorio con deriva

- Algunas series tienen una tendencia de crecimiento sostenido a largo
  plazo.

- *Paseo aleatorio con deriva*:
  #+begin_export latex
  \[
    y_t = \delta + y_{t-1} + e_t.
  \]
  #+end_export

- Si el parámetro $\delta > 0$ la variable $y_t$ tiende a crecer con
  el paso del tiempo.

** Raíces unitarias

- Un paseo aleatorio es un caso especial de un \AR{1}, donde $\rho =
  1$, incumpliendo la condición de estabilidad.

- La condición de estabilidad de procesos \AR{p} es más complicada y
  depende del valor de las raíces del *polinomio característico*: un
  polinomio de orden $p$ formado a partir de los coeficientes del
  proceso \AR{p}.

- Cuando una de esas raíces sea igual a 1, se dice que el proceso tiene
  una *raíz unitaria*.


** Raíces unitarias, tendencias estocásticas y procesos I(1)

- Si un proceso tiene una raíz unitaria entonces tiene una
  tendencia estocástica.

- La diferencia de un proceso con una raíz unitaria no tiene tendencia
  estocástica.

- Un proceso con una raíz unitaria es un proceso integrado de orden 1,
  I(1).

** Regresión espuria y tendencias estocásticas

- Si $y_t$ y $x_t$ son procesos I(1), la regresión de $y_t$ sobre
  $x_t$ mostrará con mucha frecuencia resultados muy significativos
  aunque, en realidad, las dos variables no estén relacionadas.

- Si las variables están relacionadas directamente, los residuos de la
  regresión de $y_t$ sobre $x_t$ deberían comportarse como un proceso
  I(0). En ese caso las variables están *cointegradas*.

** Regresión con variables con tendencias

- Debemos añadir un término de tendencia lineal cuando alguna de las
  variables presente tendencias deterministas.

- Las variables con raíz unitaria deben ser diferenciadas para
  eliminar las tendencias estocásticas.

- La posibilidad de que haya relaciones de cointegración entre
  variables I(1) no se explorará en este curso.


* Contrastes de raíz unitaria


** Modelo AR(1)

El modelo autorregresivo de orden 1, \AR{1}, puede escribirse como:
#+begin_export latex
\[
  y_t = \alpha + \rho y_{t-1} + u_t,
\]
#+end_export
donde $u_t$ es un ruido blanco.


** Estacionariedad y dependencia débil

Las propiedades dinámicas del proceso \AR{1} dependen del valor de $\rho$:

- $y_t$ es estacionario y débilmente dependiente si $\abs{\rho} < 1$.

- $y_t$ es un paseo aleatorio si $\rho = 1$.

- $y_t$ tiene un comportamiento explosivo cuando $\rho > 1$.


** Detección de raíces unitarias

- Los estadísticos habituales no pueden usarse para contrastar la
  existencia de una raíz unitaria.

- La estimación MCO del parámetro $\rho$ está sesgada hacia abajo y el
  sesgo aumenta cuanto más cerca está $\rho$ de 1.

- La distribución del estadístico $t = (\hat{\rho} - 1)/\se({\rho})$
  es muy diferente de una $t_{T-2}$ o de una normal cuando $\rho$
  tiene un valor cercano a 1.



** Regresión de Dickey-Fuller

- Proceso AR(1):
  #+begin_export latex
  \[
    y_t = \alpha + \rho y_{t-1} + u_t,
  \]
  #+end_export


- Restando $y_{t-1}$ de ambos lados:
  #+begin_export latex
  \[
    \incr y_t = \alpha + (\rho - 1) y_{t-1} + u_t.
  \]
  #+end_export

- Dickey y Fuller plantean contrastar la existencia de una raíz
  unitaria estimado por MCO el modelo de regresión:
  #+begin_export latex
  \[
    \incr y_t = \alpha + \beta y_{t-1} + u_t.
  \]
  #+end_export


** Contraste $\bm{t}$ de Dickey-Fuller

- Regresión de Dickey y Fuller:
  #+begin_export latex
  \[
    \incr y_t = \alpha + \beta y_{t-1} + u_t.
  \]
  #+end_export

- La existencia de una raíz unitaria implica que $\beta = 0$.

- Dickey y Fuller proponen contrastar la hipótesis nula $H_0\!: \beta =
  0$ frente a la  alternativa $H_1\!: \beta < 0$ mediante un
  contraste $t$ de una cola.


** Distribución del contraste de Dickey-Fuller

- *No debe usarse un contraste $\bm{t}$ robusto a heteroscedasticidad*. Bajo
  la hipótesis nula el contraste $t$ tradicional es válido aunque haya
  heteroscedasticidad.

- El contraste de Dickey-Fuller bajo la hipótesis nula no sigue una
  distribución normal ni ninguna otra distribución convencional.

- Los valores críticos del contraste se obtienen mediante simulación:
  #+ATTR_LATEX:  :align *{3}{@{\hspace{3mm}}r} :booktabs t
  | $10\%$  | $5\%$   | $1\%$   |
  |---------+---------+---------|
  | $-2.57$ | $-2.86$ | $-3.43$ |


** Contraste de Dickey-Fuller aumentado

- Si $y_t$ sigue un proceso \AR{p} es necesario incluir $p-1$ retardos
  de $\incr y_t$ en la regresión de Dickey-Fuller para obtener un
  contraste válido:
  #+begin_export latex
  \[
    \incr y_t =
    \alpha + \beta y_{t-1} + \phi_1 \incr y_{t-1}  +
    \phi_2 \incr y_{t-2} + \dots  + \phi_{p-1} \incr y_{t-p+1}  + u_t.
  \]
  #+end_export

- Los valores críticos de Dickey-Fuller son válidos para contrastar
  $H_0\!: \beta = 0$ frente a $H_1\!: \beta < 0$.


** Selección de retardos

- Es conveniente utilizar un criterio de información para seleccionar
  el número de retardos a incluir en la regresión de Dickey-Fuller.

- Para el constraste de Dickey-Fuller aumentado es preferible el AIC.


** Tendencias

- Si $y_t$ presenta una tendencia creciente o decreciente es
  aconsejable añadir una tendencia lineal a la regresión de
  Dickey-Fuller:
  #+begin_export latex
  \[
    \incr y_t =
    \alpha + \delta t + \beta y_{t-1} + \phi_1 \incr y_{t-1}  +
    \phi_2 \incr y_{t-2} + \dots  + \phi_{p-1} \incr y_{t-p+1}  + u_t.
  \]
  #+end_export

- Cuando se incluye una tendencia, la distribución del contraste de
  Dickey-Fuller es diferente y es necesario usar otros valores
  críticos:
  #+ATTR_LATEX:  :align *{3}{@{\hspace{3mm}}r} :booktabs t
  | $10\%$  | $5\%$   | $1\%$   |
  |---------+---------+---------|
  | $-3.12$ | $-3.41$ | $-3.96$ |



** Resumen

- Mediante la inspección de gráficos, se determina si es necesario
  incluir una tendencia lineal en la regresión de Dickey-Fuller.

- Se selecciona el número de retardos en la regresión de Dickey-Fuller
  de acuerdo con el valor del AIC.

- Se rechaza la presencia de raíz unitaria cuando el valor del
  cociente $t$ para $H_0\!: \beta = 0$ frente a $H_1\!: \beta < 0$ es
  menor que los valores críticos de la siguiente tabla:
  #+ATTR_LATEX:  :align l*{3}{@{\hspace{3mm}}r} :booktabs t
  | Tendencia lineal | $10\%$  | $5\%$   | $1\%$   |
  |------------------+---------+---------+---------|
  | No               | $-2.57$ | $-2.86$ | $-3.43$ |
  | Sí               | $-3.12$ | $-3.41$ | $-3.96$ |


* Otras cuestiones



** Multiplicadores de largo plazo (I)

- Modelo con tres retardos de la variable explicativa:
  #+begin_export latex
  \[
     y_t = \alpha + \beta_0 z_t + \beta_1 z_{t-1} + \beta_2 z_{t-2} + \beta_3 z_{t-3} + u_t.
  \]
  #+end_export

- Es posible reescribir el modelo anterior como:
  #+begin_export latex
  \[
     y_t = \alpha + \delta_0 \incr z_t + \delta_1 \incr z_{t-1} +
     \delta_2 \incr z_{t-2} + \delta_3 z_{t-3} + u_t
  \]
  #+end_export

- Con la regresión anterior se estiman directamente los
  multiplicadores acumulativos y de largo plazo y sus correspondientes
  errores típicos.


** Multiplicadores de largo plazo (y II)

- Modelo ARDL($p$, $q$):
  #+begin_export latex
  \[
     y_t = \alpha + \rho_1 y_{t-1} + \dots + \rho_p y_{t-p} +
     \beta_0 z_t + \beta_1 z_{t-1} + \dots + \beta_q z_{t-q} +
     u_t
  \]
  #+end_export

- El multiplicador de largo plazo es una función no lineal de los
  parámetros:
  #+begin_export latex
  \[
     \delta_{\text{LP}} = \frac{\sum_{j=0}^q \beta_j}{1 - \sum_{j=0}^p \rho_j}.
  \]
  #+end_export

- En este curso no se tratará como obtener los multiplicadores
  acumulativos y sus errores típicos.


** Cambio estructural

- Se produce un *cambio estructural* cuando los parámetros del modelo
  de regresión no permanecen constantes a lo largo de todo el periodo
  muestral.

- Consideraremos el caso de que los parámetros sólo cambian una vez y
  que conocemos en qué periodo se produce el cambio.


** Contraste de Chow (I)

- Modelo de regresión original:
  #+begin_export latex
  \[
    y_t = \beta_0 + \beta_1 x_{1t}  + \beta_2 x_{2t} + u_t.
  \]
  #+end_export

- El *contraste de Chow* puede usarse cuando se sospecha de la
  existencia de un cambio estructural en el periodo $\tau$, $1 < \tau
  < T$.

- Creamos una variable ficticia $D_t$ que toma el valor 0 en todos
  los periodos anteriores a $\tau$ y valor 1 a partir del periodo
  $\tau$.
  #+begin_export latex
  \[
    D_t =
    \begin{cases}
      0 & \text{si $t < \tau$}, \\
      1 & \text{si $t \geq \tau$}.
    \end{cases}
  \]
  #+end_export


** Contraste de Chow (y II)

- Añadimos al modelo original la variable $D_t$ así como
  interacciones de $D_t$ con todas las variables explicativas:
  #+begin_export latex
  \[
    y_t = \beta_0 + \beta_1 x_{1t}  + \beta_2 x_{2t} +
    \theta_0 D_t + \theta_1 D_t x_{1t}   + \theta_2 D_t x_{2t}
    + u_t.
  \]
  #+end_export

- Bajo la hipótesis nula de que no se ha producido cambio estructural
  los términos que se han añadido no son significativos.

- Puede usarse un estadístico $F$ para contrastar $\theta_0 = \theta_1
  = \theta_2 = 0$.

- En caso que se rechace la hipótesis nula, el parámetro $\theta_j$
  muestra como ha cambiado el parámetro $\beta_j$ a partir del periodo
  $\tau$.


** Estacionalidad

- Con datos trimestrales y mensuales es usual observar variables con
  fuertes oscilaciones estacionales.

- Una forma simple de controlar este tipo de variación es incluir
  *variables ficticias estacionales* en el modelo de regresión.

** Variables ficticias estacionales

- Con datos trimestrales podemos definir cuatro variables ficticias
  estacionales $D^s_t$, $s = 1, \dots, 4$:
  #+begin_export latex
  \[
    D_t =
    \begin{cases}
      0 & \text{si $t$ corresponde al trimestre $s$}, \\
      1 & \text{en caso contrario}.
    \end{cases}
  \]
  #+end_export

- En la regresión sólo incluiríamos tres de estas variables. De otra
  forma, incurriríamos en la *trampa de la variables ficticias*.

- De la misma manera, para controlar la estacionalidad en datos
  mensuales incluiríamos un conjunto de 11 variables ficticias
  estacionales.


** Desestacionalización

- Incluir variables ficticias en la regresión es equivalente a estimar
  el modelo con las variables previamente *desestacionalizadas*.

- Es frecuente encontrar variables que presentan oscilaciones
  estacionales y comportamiento tendencial. Ambos tipos de efectos
  pueden controlarse incluyendo simultáneamente una tendencia lineal y
  variables ficticias estacionales.


** COMMENT Tendencias lineales

Incluir una tendencia lineal es equivalente a:

- Eliminar la tendencia lineal de la variable dependiente, calculando
  $\ddot{y}_t$, los residuos de la regresión:
  #+begin_export latex
  \[
    y_{t} = \ahat_{0} + \ahat_{1} t + \ddot{y}_{t}
  \]
  #+end_export

- De forma similar, eliminar la tendencia lineal de cada una de las
  variables explicativas obteniendo $\ddot{x}_{1t}, \ddot{x}_{2t}, \dots, \ddot{x}_{kt}$.

- Estimar por MCO los parámetros de una regresión de $\ddot{y}_t$
  sobre $\ddot{x}_{1t}, \ddot{x}_{2t}, \dots, \ddot{x}_{kt}$.
