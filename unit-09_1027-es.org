# -*- ispell-dictionary: "spanish" -*-
#+SETUPFILE: ./course-es.org

#+TITLE: {{{unit09}}}

#+MATS: bib
#+begin_bibbox
- Wooldridge: ::  /Introducción a la Econometría/. Capítulo 10.
- Stock y Watson: ::  /Introducción a la Econometría/. Capítulo 14,
  secciones 14.6 a 14.8, y capítulo 15, secciones 15.1 a 15.3.
#+end_bibbox

* Modelos de regresión con series temporales


** Introducción

- Con series temporales es posible investigar las relaciones dinámicas
  entre variables.

- En primer lugar, examinaremos algunos modelos comúnmente utilizados.


** Modelos estáticos

- En un *modelo estático*, un cambio en una variable explicativa sólo
  tiene efectos en el periodo en que se produce y no tiene influencia
  en los periodos posteriores.

- Todas las variables del modelo se refieren al mismo periodo
  temporal:
  #+begin_export latex
  \[
    y_t = \alpha + \beta z_{t} + u_t,
  \]
  #+end_export
  donde $y_t$ es la variable dependiente, $z_t$ la variable
  explicativa, $\alpha$ y $\beta$ son parámetros desconocidos, $t = 1,
  2, \dots, T$ y $u_t$ es un término de error no observable tal que
  $\Exp(u_t | z_t) = 0$.


** Modelos de retardos distribuidos

- En un *modelo de retardos distribuidos* los cambios en las
  variables explicativas tienen efectos en más de un periodo.

- Estos modelos se caracterizan por incluir retardos de las variables
  explicativas:
  #+begin_export latex
  \[
    y_t = \alpha + \beta_0 z_{t} + \beta_1 z_{t-1} + \beta_2 z_{t-2} + \dots + \beta_L z_{t-L} + u_t,
  \]
  #+end_export
  donde $L$ es el número de retardos que aparecen en el modelo, y
  $\Exp(u_t | z_t, z_{t-1}, z_{t-2}, \dots) = 0$.


** Multiplicadores dinámicos

- El parámetro $\beta_0$ es el *multiplicador de impacto* o
  *multiplicador de corto plazo*. Es el efecto inmediato o
  contemporáneo de un cambio unitario de $z_t$ sobre $y_t$.

- Los parámetros $\beta_h$, $h = 0, 1, \dots$, son los
  *multiplicadores dinámicos* y miden el efecto de $z$ sobre $y$
  después de $h$ periodos:
  #+begin_export latex
  \[
    \iratio{y_t}{z_{t-h}} = \iratio{y_{t+h}}{z_{t}} = \beta_h.
  \]
  #+end_export


** Multiplicadores acumulativos

- Los *multiplicadores acumulativos*, $\delta_h$, suman los efectos
  que produce un cambio unitario de $z$ sobre la variable dependiente
  conforme pasa el tiempo:

  #+ATTR_LATEX: :align @{}cl@{} :booktabs t
  | Periodos transcurridos | Multiplicador acumulativo                |
  |------------------------+------------------------------------------|
  | $0$                    | $\delta_0 = \beta_0$                     |
  | $1$                    | $\delta_1 = \beta_0 + \beta_1$           |
  | $2$                    | $\delta_2 = \beta_0 + \beta_1 + \beta_2$ |
  | $\vdots$               | $\vdots$                                 |
  | $L$                    | $\delta_L = \sum_{i=0}^L \beta_i$        |

- En la última fila de la tabla aparece el *multiplicador de largo
  plazo*, $\delta_L$, que es la suma de todos los multiplicadores
  dinámicos.


** Modelos autorregresivos

- En un *modelo autorregresivo* las variables explicativas son
  retardos de la variable dependiente.

- Modelo autorregresivo de orden p, AR(p):
  #+begin_export latex
  \[
     y_t = \alpha + \rho_1 y_{t-1} + \rho_2 y_{t-2} + \dots +  \rho_p y_{t-p} + u_{t},
  \]
  #+end_export
  donde $\Exp(u_t | y_{t-1}, y_{t-2}, \dots) = 0$.


** Modelos ARDL

- Un *modelo autorregresivo con retardos distribuidos*,
  $\text{ARDL}(p, q)$, incluye como variables explicativas $p$
  retardos de $y$ y $q$ retardos de $z$:
  #+begin_export latex
  \[
    y_t =
    \alpha + \rho_1 y_{t-1} +
    \dots +
    \rho_p y_{t-p} +
    \beta_0 z_{t} +
    \beta_1 z_{t-1} +
    \dots +
    \beta_q z_{t-q} +
    u_{t},
  \]
  #+end_export
  donde $\Exp(u_t | z_t, y_{t-1}, z_{t-1}, y_{t-2}, z_{t-2}, \dots) = 0$.


* El modelo clásico de regresión con series temporales


** Introducción

- ¿Podemos usar MCO para estimar modelos de series temporales?

- ¿Qué tiene que cumplirse para que MCO tenga buenas propiedades
  exactas?



** Supuestos

Los supuestos del *modelo clásico de regresión lineal con series
temporales* son:

- *ST.1*: Linealidad en los parámetros.

- *ST.2*: Ausencia de colinealidad perfecta.

- *ST.3*: Media condicional nula.

- *ST.4*: Homoscedasticidad.

- *ST.5*: Ausencia de correlación serial.

- *ST.6*: Normalidad.


** Linealidad en los parámetros

*ST.1*: *Linealidad en los parámetros*.

El proceso estocástico $\{(y_t, x_{1t}, x_{2t}, \dots, x_{kt})\!: t = 1,
2, \dots, T\}$ sigue el modelo:
#+begin_export latex
\[
  y_t = \beta_0 + \beta_1 x_{1t} + \beta_1 x_{2t} + \dots + \beta_1 x_{kt} + u_t
\]
#+end_export
donde $\{u_t\!: t = 1, 2, \dots, T\}$ es una secuencia de perturbaciones
aleatorias no observables.



** Notación

- Nuestra especificación:
  #+begin_export latex
  \[
    y_t = \beta_0 + \beta_1 x_{1t} + \beta_1 x_{2t} + \dots + \beta_1 x_{kt} + u_t,
  \]
  #+end_export
  admite modelos dinámicos. Por ejemplo, obtenemos un modelo retardos
  distribuidos si definimos $x_{1t} = z_t, x_{2t} = z_{t-1}, \dots$

- $\bm{x_t} = (x_{1t}, x_{2t}, \dots, x_{kt})$: los valores que toman
  las explicativas en el periodo $t$.

- $\bm{X} = (\bm{x_1}, \bm{x_2}, \dots, \bm{x_T})$: los valores de
  todas las explicativas en todos los periodos de la muestra.



** Ausencia de colinealidad perfecta

*ST.2*: *Ausencia de colinealidad perfecta*.

En la muestra ninguna de las variables explicativas es constante ni
una combinación lineal perfecta de las otras explicativas.


** Media condicional nula

*ST.3*: *Media condicional nula*.

La media del término de error es $0$ condicional a los valores que
toman las explicativas en *todos* los periodos de tiempo :
#+begin_export latex
\[
  \Exp(u_t | \bm{X}) = 0,\quad t = 1, 2, \dots, T.
\]
#+end_export


** Exogeneidad estricta

*ST.3* implica que las variables explicativas son *estrictamente
exógenas*. El término de error $u_t$ debe estar incorrelacionado con
todas las explicativas en *todos* los periodos de tiempo:

- $\Exp(u_t | \bm{x_t}) = 0$: *exogeneidad contemporánea*.

- $\Exp(u_t | \bm{x_{t-1}}, \bm{x_{t-2}}, \dots, \bm{x_{1}}) =
  0$: incorrelación con valores pasados de $\bm{x_t}$.

- $\Exp(u_t | \bm{x_{t+1}}, \bm{x_{t+2}}, \dots, \bm{x_{T}}) = 0$:
  incorrelación con valores futuros de $\bm{x_t}$.



** Restricciones que impone la exogeneidad estricta

La exogeneidad estricta es incompatible con algunos casos importantes:

  + Efectos de *retroalimentación*: los valores que toma $y_t$ afectan
    a los valores futuros de las variables explicativas:
    $\bm{x_{t+1}}, \dots, \bm{x_{T}}$.

  + Modelos autorregresivos.


** Homoscedasticidad

*ST.4*: *Homoscedasticidad*.

Condicional a $\bm{X}$, la varianza de $u_t$ es la misma en todos los
periodos:
#+begin_export latex
\[
  \var(u_t | \bm{X}) = \sigma^2,\quad t = 1, 2, \dots, T.
\]
#+end_export


** Ausencia de correlación serial

*ST.5*: *Ausencia de correlación serial*.

Condicional a $\bm{X}$, las perturbaciones aleatorias de dos periodos
diferentes están incorrelacionadas:
#+begin_export latex
\[
  \corr(u_t, u_s | \bm{X}) = 0,\quad \text{para todo $t \neq s$.}
\]
#+end_export


** Normalidad

*ST.6*: *Normalidad*.

El término de error $u_t$ es independiente de $\bm{X}$ y se distribuye
independiente e idénticamente como $\Normal(0, \sigma^2)$.


** Propiedades de muestras finitas

Los supuestos del modelo clásico de regresión con series temporales
garantizan las siguientes propiedades del estimador de MCO:

- *Insesgadez*: si se cumplen *TS.1* a *TS.3*.

- *Eficiencia*: si, además, se cumplen *TS.4* y *TS.5*. En este caso,
  podemos usar las fórmulas de MCO para estimar los errores típicos de
  $\hat{\beta_j}$.

- *Normalidad*: si, además, se cumple *TS.6*. En este caso, podemos
  contrastar hipótesis con las fórmulas tradicionales de los
  contrastes $t$ y $F$.


** Limitaciones del modelo clásico

- No es posible obtener estimaciones insesgadas de los parámetros de
  modelos que incluyan retardos de la variable dependiente.

- El estimador MCO tampoco tienen buenas propiedades exactas en
  presencia de efectos de retroalimentación.

- Algunos de los supuestos del modelo clásico son muy restrictivos:
  normalidad, exogeneidad estricta, ausencia de correlación serial,
  etc.


* Propiedades asintóticas de MCO con series temporales


** Propiedades de MCO con series temporales

-  ¿Qué tiene que cumplirse para que MCO tenga buenas propiedades
  exactas?

- ¿Qué supuestos son necesarios para que se cumplan las propiedades
  asintóticas?


** Supuestos

- *TS.1'*: Linealidad y dependencia débil.
- *TS.2'*: Ausencia de colinealidad perfecta.
- *TS.3'*: Exogeneidad (contemporánea).
- *TS.4'*: Homoscedasticidad.
- *TS.5'*: Ausencia de correlación serial.


** Linealidad y dependencia débil

El proceso estocástico $\{(y_t, x_{1t}, x_{2t}, \dots, x_{kt})\!: t =
1, 2, \dots, T\}$ es *estacionario* y *débilmente dependiente* sigue
el modelo:
#+begin_export latex
\[
  y_t = \beta_0 + \beta_1 x_{1t} + \beta_1 x_{2t} + \dots + \beta_1 x_{kt} + u_t
\]
#+end_export
donde $\{u_t\!: t = 1, 2, \dots, T\}$ es la secuencia de perturbaciones
aleatorias.


** Estacionariedad

Un proceso estocástico es *(débilmente) estacionario* si:

- La media es independiente de $t$: $\Exp(x_t) = \mu$.
- La varianza es constante a lo largo del tiempo: $\var(x_t) = \sigma^2$.
- La covarianza entre $x_t$ y $x_{t + h}$ sólo depende de $h$:
  $\cov(x_{t}, x_{t+h}) = \gamma_h$.


** Dependencia débil

- Una serie $\{x_t\}$ estacionaria es *débilmente dependiente* si la
  correlación entre $x_t$ y $x_{t + h}$ decrece *rápidamente* conforme
  aumenta $h$.


** Ruido blanco

El proceso estocástico $\{e_t\}$ es un *ruido blanco* si:

- $\Exp(e_t) = 0$.

- $\var(e_t) = \sigma^2_e$.

- $\cov(e_t, e_s) = 0$, para $t \neq s$.


** Proceso autorregresivo de orden 1

- La serie $\{y_t\}$ sigue un proceso autorregresivo de orden 1,
  $\AR{1}$ si:
  #+begin_export latex
  \[
    y_{t} = \rho_{1} y_{t-1} + e_{t}
  \]
  #+end_export
  donde $e_t$ es un ruido blanco.


** Estabilidad de los procesos AR(1)

Un proceso $\AR{1}$ es *estable* si $\abs{\rho_1} < 1$. En ese caso es
estacionario y débilmente dependiente:

- $\Exp(y_t) = 0$.
- $\var(y_t) = \sigma^2_e$.
- $\corr(y_t, y_{t + h}) = \rho_1^h$.


** Procesos estacionarios con tendencia

Frecuentemente se usa la denominación de *proceso estacionario con
tendencia* para series que siguen:
#+begin_export latex
\[
  y_t = \alpha_0 + \alpha_1 t + u_t
\]
#+end_export
donde $u_t$ es un proceso estacionario y débilmente dependiente.


** Exogeneidad contemporánea

- Las variables explicativas $\bm{x}_t$ son *contemporáneamente exógenas*:
  #+begin_export latex
  \[
    \Exp(u_{t}|\bm{x}_{t}) = 0.
  \]
  #+end_export

- Este supuesto no excluye fenómenos de retroalimentación ni
  autorregresiones.


** Homoscedasticidad y ausencia de autocorrelación

- Homoscedasticidad: $\var(u_t|\bm{x}_t) = \sigma^2$.

- No correlación serial: $\corr(u_t, u_s | \bm{x}_t, \bm{x}_s) = 0$.


** Propiedades asintóticas

- *Consistencia*: si se cumplen *TS.1'* a *TS.3'*.

- *Normalidad asintótica*: si además se cumplen *TS.4'* y *TS.5'*.


* Otras cuestiones


** Regresión espuria

- *Regresión espuria*: Encontrar una relación aparente entre dos o más
  variables que presentan tendencias pero que no tienen relación entre
  sí.

- Factores no observables provocan tendencias en la dependiente y las
  explicativas.

- Una solución simple es incluir una tendencia lineal como un regresor
  adicional.


** Tendencias lineales

Incluir una tendencia lineal es equivalente a:

- Eliminar la tendencia lineal de la variable dependiente, calculando
  $\ddot{y}_t$, los residuos de la regresión:
  #+begin_export latex
  \[
    y_{t} = \ahat_{0} + \ahat_{1} t + \ddot{y}_{t}
  \]
  #+end_export

- De forma similar, eliminar la tendencia lineal de cada una de las
  variables explicativas obteniendo $\ddot{x}_{1t}, \ddot{x}_{2t}, \dots, \ddot{x}_{kt}$.

- Estimar por MCO los parámetros de una regresión de $\ddot{y}_t$
  sobre $\ddot{x}_{1t}, \ddot{x}_{2t}, \dots, \ddot{x}_{kt}$.


** Estacionalidad

- Con datos trimestrales y mensuales es usual observar variables con
  fuertes oscilaciones estacionales.

- Una forma simple de controlar este tipo de fluctuaciones es incluir
  *variables ficticias estacionales* en el modelo de regresión.


** Desestacionalización

- Incluir variables ficticias en la regresión es equivalente a estimar
  el modelo con las variables previamente *desestacionalizadas*.

- Es frecuente encontrar variables que presentan oscilaciones
  estacionales y comportamiento tendencial. Ambos tipos de efectos
  pueden controlarse incluyendo simultáneamente una tendencia lineal y
  variables ficticias estacionales.
